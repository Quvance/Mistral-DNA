{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Raphael Mourad\n",
    "### Associate Professor\n",
    "### University Paul Sabatier / INRAE MIAT Lab Toulouse\n",
    "### 20/12/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADAPTED FROM https://gist.github.com/neoyipeng2018/cbe64b40ad683ff50b15fb67fa39fabd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 14:49:31.189113: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-16 14:49:31.328221: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-16 14:49:31.730836: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/lib/x86_64-linux-gnu\n",
      "2024-01-16 14:49:31.731041: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvrtc.so.11.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/lib/x86_64-linux-gnu\n",
      "2024-01-16 14:49:31.731048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoModelForPreTraining\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import DataCollatorForLanguageModeling, TextDataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "from peft import PeftModel, PeftConfig, LoftQConfig\n",
    "from peft import LoraConfig, get_peft_model, get_peft_model_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark=True\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:32 \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/mourad/SSD2/MistralDNA\n"
     ]
    }
   ],
   "source": [
    "#Â SET DIRECTORY\n",
    "os.chdir(\"/media/mourad/SSD2/MistralDNA/\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    #model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "    config = AutoConfig.from_pretrained(\"google/switch-base-8\")\n",
    "    model = AutoModelForPreTraining.from_config(config)\n",
    "    #model = AutoModelForCausalLM.from_config(config)\n",
    "    model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(4096, 32, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 32)\n",
       "      (token_type_embeddings): Embedding(2, 32)\n",
       "      (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=32, out_features=256, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=256, out_features=32, bias=True)\n",
       "            (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=32, out_features=256, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=256, out_features=32, bias=True)\n",
       "            (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=32, out_features=256, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=256, out_features=32, bias=True)\n",
       "            (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=32, out_features=256, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=256, out_features=32, bias=True)\n",
       "            (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=32, out_features=256, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=256, out_features=32, bias=True)\n",
       "            (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=32, out_features=256, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=256, out_features=32, bias=True)\n",
       "            (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=32, out_features=256, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=256, out_features=32, bias=True)\n",
       "            (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=32, out_features=256, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=256, out_features=32, bias=True)\n",
       "            (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=32, out_features=4096, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DNABERT2 (ONLY LOAD MODEL ARCHITECTURE NOT WEIGTHS)\n",
    "config = AutoConfig.from_pretrained(\"data/models/DNABERT-2-117M/\")\n",
    "#model = AutoModelForPreTraining.from_config(config)\n",
    "model = AutoModelForMaskedLM.from_config(config)#\"flash_attention_2\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"data/models/DNABERT-2-117M/\",\n",
       "  \"alibi_starting_size\": 512,\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.0,\n",
       "  \"auto_map\": {\n",
       "    \"AutoConfig\": \"configuration_bert.BertConfig\",\n",
       "    \"AutoModel\": \"bert_layers.BertModel\",\n",
       "    \"AutoModelForMaskedLM\": \"bert_layers.BertForMaskedLM\",\n",
       "    \"AutoModelForSequenceClassification\": \"bert_layers.BertForSequenceClassification\"\n",
       "  },\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 32,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 256,\n",
       "  \"layer_norm_eps\": 1000000000000.0,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 8,\n",
       "  \"num_hidden_layers\": 8,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.37.0.dev0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 4096\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='songlab/gpn-arabidopsis', vocab_size=6, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'pad_token': '[PAD]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "{'input_ids': tensor([[2, 5, 5, 4, 5, 4, 4, 4, 5, 3, 3, 3, 3, 3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(6, 32)\n",
       "      (position_embeddings): Embedding(512, 32)\n",
       "      (token_type_embeddings): Embedding(2, 32)\n",
       "      (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=32, out_features=256, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=256, out_features=32, bias=True)\n",
       "            (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=32, out_features=256, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=256, out_features=32, bias=True)\n",
       "            (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=32, out_features=256, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=256, out_features=32, bias=True)\n",
       "            (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=32, out_features=256, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=256, out_features=32, bias=True)\n",
       "            (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=32, out_features=256, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=256, out_features=32, bias=True)\n",
       "            (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=32, out_features=256, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=256, out_features=32, bias=True)\n",
       "            (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=32, out_features=256, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=256, out_features=32, bias=True)\n",
       "            (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=32, out_features=256, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=256, out_features=32, bias=True)\n",
       "            (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((32,), eps=1000000000000.0, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=32, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD DNA LETTER TOKENIZER\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=\"songlab/gpn-arabidopsis\")\n",
    "print(tokenizer)\n",
    "\n",
    "encoding = tokenizer(\"ATTGTGGGTCCCCC\", padding=\"longest\", truncation=True, return_tensors=\"pt\")\n",
    "print(encoding)\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 0.2M parameters\n"
     ]
    }
   ],
   "source": [
    "#Â NUMBER OF MODEL PARAMETERS\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model size: {pytorch_total_params/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â LOAD DATA (CANNOT HANDLE LARGE TEXT FILES)\n",
    "if False:\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    "    )\n",
    "\n",
    "    dataset = TextDataset(\n",
    "        tokenizer=tokenizer,\n",
    "        file_path='data/genome_sequences/hg38/sequences_hg38_200b.tsv',\n",
    "        block_size=200,\n",
    "    )\n",
    "\n",
    "    print(len(dataset))\n",
    "    print(dataset[1].shape)\n",
    "\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_set, val_set = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "    train_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Â LOAD DATA \n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    "    )\n",
    "\n",
    "dataset_text = load_dataset(\"csv\", data_files=\"data/genome_sequences/hg38/sequences_hg38_200b_2.csv\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"longest\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "dataset = dataset_text.map(tokenize_function, batched=True)\n",
    "print(dataset[\"train\"])\n",
    "\n",
    "train_size = int(0.8 * len(dataset[\"train\"]))\n",
    "test_size = len(dataset[\"train\"]) - train_size\n",
    "train_set, val_set = torch.utils.data.random_split(dataset[\"train\"], [train_size, test_size])\n",
    "train_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PARAMETERS FOR FINE-TUNING\n",
    "batchsize=128\n",
    "training_args = TrainingArguments(\n",
    "        output_dir='./results/models',\n",
    "        evaluation_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        num_train_epochs=50,\n",
    "        per_device_train_batch_size=batchsize,\n",
    "        per_device_eval_batch_size=batchsize,\n",
    "        learning_rate=1e-4,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        load_best_model_at_end=True,\n",
    "        fp16=True,\n",
    "        gradient_accumulation_steps=50,\n",
    ")\n",
    "\n",
    "print(training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Â PRETRAIN MODEL\n",
    "# with small model (186022 params), 100h / 50 epochs = 2h / epoch\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=val_set,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    " \n",
    "print ('Start a trainer...')\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string=[\"CGACCCTACTTCCCGCGGCCCCGGACGCCTCCTCACCTGCGAGCCGCCCTCCCGGAAGCTCCCGCCGCCGCTTCCGCT[MASK]TGCCGGAGCCGCTGGGTCCTAGCCCCGCCGCCCACAGTCCGCCCGCGCCTCCGGGTCCTAACGCCGCCGCTCGCCCTCCGCTGCGCCCTCCCCGAGCGCGGCTCCAGGACCCCGTCGACCC\"]*2\n",
    "input_string\n",
    "\n",
    "tokenized_inputs = tokenizer(input_string, return_tensors=\"pt\")\n",
    "outputs=model(tokenized_inputs[\"input_ids\"].cuda())\n",
    "outputs\n",
    "\n",
    "probs=torch.nn.functional.softmax(outputs['logits'],2)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_string=[\"CGACCCTACTTCCCGCGGCC[MASK]TGCCGTCCAGGACCCCGTCGACCC\"]*2\n",
    "input_string\n",
    "\n",
    "tokenized_inputs = tokenizer(input_string, return_tensors=\"pt\")\n",
    "outputs=model(tokenized_inputs[\"input_ids\"].cuda())\n",
    "outputs\n",
    "\n",
    "probs=torch.nn.functional.softmax(outputs['logits'],2)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
